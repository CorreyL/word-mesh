Market risk refers to the risk of losses in the bank’s trading book due to changes in equity prices, interest rates, credit
spreads, foreign-exchange rates, commodity prices, and other indicators whose values are set in a public market. To
manage market risk, banks deploy a number of highly sophisticated mathematical and statistical techniques. Chief
among these is value-at-risk (VAR) analysis, which over the past 15 years has become established as the industry and
regulatory standard in measuring market risk.
The demands placed on VAR and other similar techniques have grown tremendously, driven by new products such as
correlation trading, multi-asset options, power-reverse dual currency swaps, swaps whose notional value amortizes
unpredictably, and dozens of other such innovations. To keep up, the tools have evolved. For example, the number of
risk factors required to price the trading book at a global institution has now grown to several thousand, and sometimes
as many as 10,000. Valuation models have become increasingly complex. And most banks are now in the process of
integrating new stress-testing analytics that can anticipate a broad spectrum of macroeconomic changes.
Despite these accomplishments, VAR and other risk models have continually come up short. The 1998 crisis at Long
Term Capital Management demonstrated the limitations of risk modeling. In the violent market upheavals of 2007–08,
many banks reported more than 30 days when losses exceeded VAR, a span in which 3 to 5 such days would be the
norm. In 2011, just before the European sovereign crisis got under way, many banks’ risk models treated eurozone
government bonds as virtually risk free.
Indeed, the perceived limitations of VAR are bringing the industry under severe scrutiny. As one pundit puts it: “A decade
rarely passes without a market event that some respected economist claims, with a straight face, to be a perfect storm, a
10-sigma event, or a catastrophe so fantastically improbable that it should not have been expected to occur in the entire
history of the universe from the big bang onward.” 1
In the wake of the most recent troubles, critics have noted VAR’s reliance on normal market distributions and its
fundamental assumption that positions can be readily liquidated. Regulators have attempted to compensate for some
of these limitations, notably through Basel II.5, a comprehensive upgrade to the market-risk framework that took effect
in December 2011. Some new elements in the framework, such as a requirement to calculate stressed VAR, are driving
risk-weighted assets (RWAs) higher and boosting capital requirements by a factor of two to three. 2 (Basel III will bump
the stakes even higher, notably through the introduction of the credit-valuation adjustment (CVA), which measures the
market risk in OTC derivatives from counterparty credit spreads.)
The imposition of higher capital requirements may make the financial system safer, but from a modeling perspective this
is a fairly blunt instrument. The ongoing refinements in stress testing are a welcome complement to the main work on
VAR, but almost all banks would agree that risk models need more work. Banks are curious about the design choices
entailed in simulation and valuation; they are probing for the right balance between sophistication and accuracy, on the
one hand, and simplicity, transparency, and speed on the other. Having high-quality market data turns out to be just as
critical as the models themselves, but many banks are uncertain about where to draw the line between acceptable and
unacceptable levels of quality.
